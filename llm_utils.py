"""
llm_utils.py

This module handles all interactions with the LLM to facilitate
dialogic, personalized English vocabulary and reading comprehension learning.

Functions include:
- Generating vocabulary prompts and hints
- Evaluating student answers for meaning accuracy
- Giving correct-answer praise messages
- Producing final explanations and scaffolded teaching content

Used throughout the system for all student-facing instructional messaging.
"""

from openai import OpenAI
import config
import sheet_utils

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=config.OPENROUTER_API_KEY,
)

# General system prompt for GrowTalk
system_prompt_reading = f"""ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™ IELTS è‹±æ–‡å˜…è€å¸«ï¼Œèªæ°£æº«æŸ”ã€é¼“å‹µæ€§å¼·ï¼Œæ“…é•·å¼•å°å­¸ç”Ÿæ€è€ƒï¼Œä¸¦å–„ç”¨ Dialogic æ•™å­¸æ³•ï¼ŒåŒ…æ‹¬ä½¿ç”¨ã€Œå­¸è¡“æ€§äº’å‹•èªªè©±æŠ€å·§ã€ï¼ˆAcademically Productive Talkï¼‰åšŸå¹«åŠ©å­¸ç”Ÿç™¼å±•æ€ç¶­ã€‚

    ä½ æœƒä½¿ç”¨ä»¥ä¸‹äº’å‹•ç­–ç•¥ï¼ˆTalk Movesï¼‰ï¼š

    è½‰å‘èˆ‡è¨è«–ï¼ˆTurn and Talkï¼‰ï¼šé¼“å‹µå­¸ç”Ÿå…ˆåŒèº«é‚Šå˜…åŒå­¸åˆ†äº«è«—æ³•ï¼Œå»ºç«‹è‡ªä¿¡ã€‚

    é‡è¿°ï¼ˆRevoicingï¼‰ï¼šå°‡å­¸ç”Ÿè¬›å˜…å˜¢é‡è¿°ä¸€éï¼Œç¢ºèªç†è§£ï¼Œå¹«åŠ©ä½¢å“‹ç”±å£èªéæ¸¡åˆ°æ›´æº–ç¢ºå˜…è‹±æ–‡ã€‚

    è£œå……ï¼ˆAdding Onï¼‰ï¼šé¼“å‹µå­¸ç”Ÿå»ºç«‹å–ºä»–äººè¬›æ³•ä¸Šå†ç™¼å±•ã€‚

    æ¨ç†èˆ‡è§£é‡‹ï¼ˆReasoningï¼‰ï¼šå¼•å°å­¸ç”Ÿè¬›è§£é»è§£ä½¢å’è«—ï¼Œæå‡ºè­‰æ“šã€‚

    ä¿®æ­£æ€ç¶­ï¼ˆRevise Thinkingï¼‰ï¼šé¼“å‹µå­¸ç”Ÿå–ºè½å®Œå…¶ä»–äººæ„è¦‹ä¹‹å¾Œï¼Œåæ€è‡ªå·±åŸæœ¬å˜…ç­”æ¡ˆã€‚

    ä½ æœƒä»¥å»£æ±è©±è§£é‡‹ IELTS è€ƒè©¦å…¥é¢å˜…è‹±æ–‡å°ˆæ¥­è©å½™ï¼Œä¾‹å¦‚ï¼š

    Noun (åè©)ï¼šæŒ‡äººã€åœ°æ–¹ã€äº‹ç‰©æˆ–æ¦‚å¿µï¼Œä¾‹å¦‚ â€œbookâ€, â€œhappinessâ€ã€‚

    Skimming (ç•¥è®€æ³•)ï¼šå¿«é€Ÿè®€æ–‡ï¼Œæµå‡ºæ¯æ®µä¸»æ—¨å¥ï¼ˆtopic sentenceï¼‰ï¼Œäº†è§£å¤§æ„ã€‚

    Scanning (å°‹è®€æ³•)ï¼šå¸¶ä½å•é¡Œå¿«é€Ÿæœå°‹æ–‡ç« å…§å˜…é—œéµå­—ã€‚

    Gist (å¤§æ„ / ä¸»æ—¨)ï¼šæ–‡ç« ä¸»è¦æƒ³è¬›ä¹œã€‚

    Topic Sentence (ä¸»é¡Œå¥)ï¼šé€šå¸¸ä¿‚æ®µè½ç¬¬ä¸€å¥ï¼Œå¹«åŠ©ç†è§£æ•´æ®µé‡é»ã€‚

    ä½ æœƒå› æ‡‰å­¸ç”Ÿå›æ‡‰ä½œå‡ºé‡å°æ€§æå•æˆ–é¼“å‹µï¼Œä¾‹å¦‚ï¼š

    ã€Œä½ å¯å””å¯ä»¥è§£é‡‹å¤šå•²ä½ é»è«—å˜…ï¼Ÿã€

    ã€Œä½ åŒä½ æ‹æª”è¬›å’—å•²å’©ï¼Ÿå¯ä»¥åˆ†äº«ä¸€ä¸‹ï¼Ÿã€

    ã€Œä½ æ”¹è®Šå’—è«—æ³•æœªï¼Ÿé»è§£ï¼Ÿã€

    æ•™å­¸ç›®æ¨™ä¿‚å¹«åŠ©å­¸ç”Ÿå””å–®æ­¢è­˜åšé¡Œç›®ï¼Œæ›´åŠ ç†è§£èªè¨€èƒŒå¾Œå˜…çµæ§‹åŒé‚è¼¯ï¼Œé€æ­¥å»ºç«‹é–±è®€ç­–ç•¥ï¼ŒåŒ…æ‹¬ Surveyingã€Skimming åŒ Scanningã€‚"""

system_prompt_vocab = f"""ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡è©å½™å˜… IELTS è€å¸«ï¼Œèªæ°£æº«æŸ”ã€é¼“å‹µæ€§å¼·ï¼Œæ“…é•·é€éã€Œäº’å‹•èªªè©±æŠ€å·§ã€ï¼ˆTalk Movesï¼‰å¼•å°å­¸ç”Ÿå­¸æ–°è©ï¼Œå””æ­¢ä¿‚è¨˜è©èªï¼Œè€Œä¿‚ç†è§£ç”¨æ³•ã€é€ å¥åŒæ‡‰ç”¨ç­–ç•¥ã€‚

    ä½ æœƒä½¿ç”¨ä»¥ä¸‹äº’å‹•å¼æ•™å­¸æŠ€å·§ï¼š

    Revoicingï¼ˆé‡è¿°ï¼‰ï¼šå¹«å­¸ç”Ÿé‡è¿°ä½¢å“‹è¬›éå˜…æ„æ€ï¼ŒåŠ å¼·ç†è§£ã€‚

    Reasoningï¼ˆæ¨ç†ï¼‰ï¼šå¼•å°å­¸ç”Ÿè§£é‡‹é»è§£é¸æ“‡å‘¢å€‹è©èªï¼Œæˆ–è€…é»æ¨£å¾ä¸Šä¸‹æ–‡æ¨æ¸¬æ„æ€ã€‚

    Turn and Talkï¼ˆè½‰å‘èˆ‡è¨è«–ï¼‰ï¼šé¼“å‹µå­¸ç”Ÿå…ˆåŒæ‹æª”äº¤æµï¼Œå†ç”¨è‡ªå·±æ–¹å¼è¬›ä¸€æ¬¡ã€‚

    Revise Thinkingï¼ˆä¿®æ­£æ€ç¶­ï¼‰ï¼šé¼“å‹µå­¸ç”Ÿæ ¹æ“šæ–°ä¾‹å­æˆ–è§£é‡‹ä¿®æ­£å°è©ç¾©å˜…ç†è§£ã€‚

    Adding Onï¼ˆè£œå……ï¼‰ï¼šå¼•å°å­¸ç”Ÿè¬›å¤šå•²ï¼Œä¾‹å¦‚è©æ€§ã€åŒç¾©è©ã€å¸¸ç”¨æ­é…ã€‚

    ä½ æœƒä»¥å»£æ±è©±è§£é‡‹è‹±æ–‡è©å½™ï¼Œä¾‹å¦‚ï¼š

    Verbï¼ˆå‹•è©ï¼‰ï¼šæè¿°å‹•ä½œæˆ–ç‹€æ…‹ï¼Œä¾‹å¦‚ â€œrunâ€, â€œbelieveâ€ã€‚

    Collocationï¼ˆè©èªæ­é…ï¼‰ï¼šå¸¸è¦‹é…æ­ï¼Œä¾‹å¦‚ â€œmake a decisionâ€ æˆ– â€œheavy rainâ€ã€‚

    Root wordï¼ˆè©æ ¹ï¼‰ï¼šè©èªå˜…åŸºæœ¬å½¢å¼ï¼Œä¾‹å¦‚ â€œactâ€ â†’ â€œactionâ€, â€œactiveâ€, â€œactorâ€ã€‚

    Context cluesï¼ˆèªå¢ƒæç¤ºï¼‰ï¼šæ ¹æ“šå¥å­å…¶ä»–å­—æ¨æ¸¬æ–°è©æ„æ€ã€‚

    ä½ æœƒç”¨å•å¥å¼•å°å­¸ç”Ÿï¼Œä¾‹å¦‚ï¼š

    ã€Œä½ è¦ºå¾—å‘¢å€‹å­—ä¿‚å½¢å®¹è©å®šå‹•è©ï¼Ÿé»è§£ï¼Ÿã€

    ã€Œä½ å¯ä»¥è¬›ä¸€å€‹ç”¨åˆ°å‘¢å€‹å­—å˜…å¥å­ï¼Ÿã€

    ã€Œä½ è½éé¡ä¼¼å˜…è©èªæœªï¼Ÿæœ‰å†‡ä¹œè¯æƒ³ï¼Ÿã€

    æ•™å­¸ç›®æ¨™ä¿‚å¹«åŠ©å­¸ç”Ÿå­¸è­˜ç”¨è©ï¼Œè€Œå””åªä¿‚èƒŒè©ã€‚ä½ æœƒå¼•å°å­¸ç”Ÿè­˜å¾—ï¼š

    çŒœè©ç¾©ï¼ˆfrom contextï¼‰

    è¾¨è©æ€§ï¼ˆnoun, verb, adjectiveï¼‰

    æ­é…ä½¿ç”¨ï¼ˆcollocationsï¼‰

    è®ŠåŒ–å½¢ï¼ˆword formsï¼‰

    IELTS å¸¸è¦‹é«˜é »è©ï¼ˆacademic word listï¼‰"""

"""
##############
GENERAL
##############
"""


def greet_student(student_name: str) -> str:
    """
    Generate a warm and encouraging greeting message to student

    The message introduces the student to today's training topic and invites the student to reply with "I'm ready"
    to begin.

    Parameters:
        student_name (str): Student name

    Returns:
        str: Cantonese greeting message generated by the LLM
    """

    prompt = (
        """è«‹ä½ ä»¥ä¸€ä½æº«æŸ”ã€æœ‰åŒç†å¿ƒã€é¼“å‹µå­¸ç”Ÿå˜—è©¦å˜…è‹±æ–‡è€å¸«èº«ä»½ï¼Œå‘ä¸€ç­å»£æ±è©±ç‚ºæ¯èªå˜…ä¸­å­¸ç”Ÿç™¼å‡ºä¸€å€‹æº«æš–é‚€è«‹ï¼Œé¼“å‹µä½¢å“‹åƒåŠ ä»Šæ—¥å˜…è‹±èªç·´ç¿’æ™‚é–“ã€‚èªæ°£è¦è¦ªåˆ‡ã€æœ‰è¶£ã€å…·å•Ÿç™¼æ€§

        Student Name: {student_name}

        Sample: Hello {student_name}ï½ğŸ‘‹
        ä»Šæ—¥æˆ‘æº–å‚™å’—ä¸€å€‹å¥½è¼•é¬†åˆå¯¦ç”¨å˜…è‹±æ–‡å°ç·´ç¿’ğŸ˜

        ğŸ§¡ä½ æº–å‚™å¥½ä¸€é½ŠæŒ‘æˆ°ä»Šæ—¥å˜…ä»»å‹™æœªï¼Ÿå°±ç®—è‹±æ–‡å””ä¿‚ä½ æœ€å¥½å—°ç§‘ï¼Œåªè¦ä½ è‚¯è©¦ï¼Œæˆ‘å“‹å°±å·²ç¶“è¸å‡ºå’—é‡è¦ä¸€æ­¥å•¦ï¼

        ä¸€é½ŠåŠ æ²¹ï¼Œæˆ‘ç­‰ç·Šä½ ï½ğŸ’ªğŸ“š

        Keep it between 20-30 words

        No need to do translation into english, just keep the conversation in Cantonese 

        Require the student to reply "vocab" to start the vocab training when they are ready
        """
    ).format(student_name=student_name)

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_vocab},
            {"role": "user", "content": prompt},
        ],
    )
    return response.choices[0].message.content


def evaluate_answer(user_answer: str, correct_answer: str) -> bool:
    """
    Return True or False
    Check whether the user's answer is correct, based on the meaning rather than exact wording.

    Parameters:
        user_answer (str): student's answer.
        correct_answer (str): model answer.

    Returns:
        bool: True if the LLM determines the answer is correct, else False.
    """
    prompt = f"""
    ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™æ›¸å˜…è‹±æ–‡è€å¸«

    ä½ è€Œå®¶è¦è©•ä¼°å­¸ç”Ÿå°æŸæ¢å•é¡Œå˜…å›ç­”ï¼Œç‡ä¸‹ä½¢ç­”å¾—å•±å””å•±ã€‚

    âœ… è«‹ä½ åªç”¨ä»¥ä¸‹ JSON æ ¼å¼å›è¦†ï¼Œä¸éœ€è¦å…¶ä»–èªªæ˜æˆ–è§£é‡‹ï¼š

    {{
    "is_correct": true/false
    }}

    è³‡æ–™å¦‚ä¸‹ï¼š

    ğŸ’¬ å­¸ç”Ÿç­”æ¡ˆï¼š
    {user_answer}

    ğŸ“– æ¨™æº–ç­”æ¡ˆï¼ˆæ„æ€æ–¹å‘ï¼‰ï¼š
    {correct_answer}

    è«‹å°å¿ƒåˆ†æèªæ„ï¼Œå†åˆ¤æ–·å­¸ç”Ÿç­”æ³•ä¿‚å’ªæ¥è¿‘æ­£ç¢ºã€‚
    """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_vocab,
            },
            {"role": "user", "content": prompt},
        ],
    )

    reply = response.choices[0].message.content.strip()

    # Parse the JSON-like response
    try:
        if '"is_correct": true' in reply.lower():
            return True
        elif '"is_correct": false' in reply.lower():
            return False
        else:
            raise ValueError(f"Unexpected LLM response: {reply}")
    except Exception as e:
        print(f"âš ï¸ Failed to interpret LLM response: {reply}")
        raise e


def is_student_answering_question(user_reply: str, question_prompt: str) -> bool:
    """
    Uses LLM to determine whether the student is attempting to answer the actual question prompt.

    Parameters:
        user_reply (str): The student's message.
        question_prompt (str): The question the bot asked (e.g. 'ä½ çŸ¥å””çŸ¥é“ "adapt" å˜…æ„æ€ï¼Ÿ').

    Returns:
        bool: True if the reply is a direct or indirect answer to the question, else False.
    """
    prompt = f"""
    ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

    ä½ å•å­¸ç”Ÿï¼š
    ã€Œ{question_prompt}ã€

    è€Œå­¸ç”Ÿå˜…å›æ‡‰ä¿‚ï¼š
    ã€Œ{user_reply}ã€

    è«‹åˆ¤æ–·ä¸€ä¸‹å­¸ç”Ÿå˜…å›ç­”ä¿‚å””ä¿‚å›æ‡‰ç·Šä½ å•å˜…å•é¡Œï¼Ÿ

    âœ… å¦‚æœä½¢å˜…å›ç­”ä¿‚ç›´æ¥å›æ‡‰ç·Šä½ å˜…å•é¡Œå˜…è©± â†’ å›è¦†ï¼š
    {{"answered": true}}

    âŒ å¦‚æœä½¢ä¿‚å›æ‡‰ç·Šå¦ä¸€æ¨£å˜¢æˆ–è€…ä¿‚å•ç·Šå¦ä¸€å€‹å•é¡Œå˜…è©±ï¼ˆè¬›ç¬‘ã€è½‰è©±é¡Œã€ç„¡é—œæå•ï¼‰â†’ å›è¦†ï¼š
    {{"answered": false}}

    è«‹åªç”¨ JSON æ ¼å¼å›è¦†ï¼Œå””å¥½åŠ è§£é‡‹ã€‚
    """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_reading},
            {"role": "user", "content": prompt},
        ],
    )

    reply = response.choices[0].message.content.lower()
    return '"answered": true' in reply


def is_reply_relevant_to_learning(user_reply: str, current_question: str) -> bool:
    """
    Uses LLM to determine whether the student's message is relevant to the learning task
    or English learning in general.

    Parameters:
        user_reply (str): The student's message.
        current_question (str): The current English learning prompt/question.

    Returns:
        bool: True if relevant to English learning, else False.
    """
    prompt = f"""
    ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

    å­¸ç”Ÿå•±å•±å›æ‡‰å’—ä¸€æ®µè¨Šæ¯ï¼Œä½ è¦åˆ¤æ–·ä½¢è¬›å˜…å…§å®¹ï¼Œä¿‚å””ä¿‚åŒè‹±æ–‡å­¸ç¿’é—œã€‚

    ä»¥ä¸‹ä¿‚ä½ å•ä½¢å˜…å•é¡Œï¼š
    ã€Œ{current_question}ã€

    ä»¥ä¸‹ä¿‚å­¸ç”Ÿå˜…å›æ‡‰ï¼š
    ã€Œ{user_reply}ã€

    è«‹ä½ åˆ¤æ–·å­¸ç”Ÿä¿‚å’ªï¼š
    âœ… æ­£å¸¸å›æ‡‰å•é¡Œã€å•è‹±æ–‡å•é¡Œã€æƒ³å­¸è‹±æ–‡ â†’ å›è¦†ï¼š{{"relevant": true}}
    âŒ è¬›å…¶ä»–ç„¡é—œè©±é¡Œï¼ˆä¾‹å¦‚ï¼šç…®é£¯ã€AIä¿‚å’©ã€å¤©æ°£ã€ç„¡å˜é ­ï¼‰â†’ å›è¦†ï¼š{{"relevant": false}}

    e.g.: æƒ³å•å“bookå‘¢å€‹å­—å¯å””å¯ä»¥è½‰åšå‹•è©ï¼Ÿ is relevant
    e.g.: æƒ³å•å“è‹±æ–‡è£é¢nounä¿‚ä¹œå˜¢æ„æ€ï¼Ÿ is relevant


    å””éœ€è¦å…¶ä»–èªªæ˜ï¼Œåªç”¨ JSON æ ¼å¼å›è¦†ã€‚
    """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_vocab},
            {"role": "user", "content": prompt},
        ],
    )

    reply = response.choices[0].message.content.lower()
    return '"relevant": true' in reply


def generate_answer_to_student_question(user_question: str) -> str:
    """
    Use LLM to generate answer to student's english related question
    """

    prompt = f"""
    ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

    å­¸ç”Ÿå•å’—ä¸€æ¢æœ‰é—œè‹±æ–‡å­¸ç¿’å˜…å•é¡Œï¼Œè«‹ä½ ç”¨è¦ªåˆ‡ã€ç°¡å–®æ–¹å¼è§£ç­”ä½¢ï¼Œä¸¦å¼•å°ä½¢ç¹¼çºŒè¿”å­¸ç¿’ä»»å‹™ã€‚

    å•é¡Œï¼š
    ã€Œ{user_question}ã€

    è«‹ç”¨å»£æ±è©±å›ç­”ï¼Œ80â€“100 å­—å…§ï¼Œå””å¥½åé›¢ä¸»é¡Œå¤ªé ã€‚
    """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_vocab},
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


"""
##############
READING EXERCISE
##############
"""


def generate_question_message(question: str, student_name: str = None) -> str:
    """
    Appends the provided question
    Uses the LLM to generate a warm Cantonese encouragement message

    Parameters:
        question (str): The comprehension question (unchanged in output).
        student_name (str, optional): The name of the student for personalization.

    Returns:
        str: A message to send to the student.
    """
    name_text = f"{student_name}ï½ğŸ‘‹ " if student_name else ""

    prompt = f"""
        ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™æ›¸å˜…è‹±æ–‡è€å¸«ï¼Œæ€§æ ¼æº«æŸ”ã€æœ‰åŒç†å¿ƒï¼Œæ“…é•·ä»¥è¦ªåˆ‡èªæ°£é¼“å‹µå­¸ç”ŸæŠ•å…¥é–±è®€ç†è§£ä»»å‹™ã€‚

        è«‹å¯«ä¸€æ®µ 60â€“80 å­—å˜…å»£æ±è©±é¼“å‹µèªå¥ï¼Œèªæ°£å¯ä»¥åŠ å…¥ emojiï¼Œèªè¨€è¼•é¬†æº«æš–ï¼Œç›®æ¨™ä¿‚ä»¤å­¸ç”Ÿæ¨‚æ„å›ç­”å•é¡Œã€‚

        ä¹‹å¾Œæˆ‘æœƒå°‡è€å¸«å¯«å˜…é¼“å‹µå¥ + å•é¡Œé€ä¿¾å­¸ç”Ÿã€‚

        No need to say hi to everyone in the encouragement message
        """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_reading},
            {"role": "user", "content": prompt},
        ],
    )

    encouragement = response.choices[0].message.content.strip()

    # Combine into final message
    full_message = f"""
    ğŸ§¡ {name_text}{encouragement}

â“ *å•é¡Œï¼š*
{question.strip()}

è«‹ä½ æ ¹æ“šä¸Šé¢å˜…å…§å®¹ï¼Œè©¦å“å›ç­”å‘¢æ¢å•é¡Œï½
"""
    return full_message.strip()


def give_hint_or_explanation(
    user_answer: str,
    correct_answer: str,
    question_text: str,
    passage: str,
    attempt: int,
) -> str:
    """
    Only call when the answer is incorrect
    Provides hint or explanation based on the number of attempts.

    Parameters:
        user_answer (str): The student's response.
        correct_answer (str): The expected answer.
        question_text (str): The original question.
        attempt (int): Current attempt (1â€“3)

    Logic:
        Attempt	Bot Response Type	Purpose
        1st attempt	- Minor hint > Encourage thinking, low pressure
        2nd attempt	- Stronger hint	> Guide toward key concept
        3rd attempt	- Reveal + explain > Give correct answer with explanation, invite reflection

    Returns:
        str: Cantonese feedback message (hint or explanation)
    """
    if attempt < 1 or attempt > 3:
        raise ValueError("Attempt must be between 1 and 3")

    if attempt == 3:
        tone = "æº«æŸ”è€Œæ¸…æ¥š"
        task = f"""å­¸ç”Ÿå·²ç¶“è©¦å’—ä¸‰æ¬¡éƒ½æœªç­”å•±ã€‚è«‹ä½ æä¾›æ­£ç¢ºç­”æ¡ˆã€Œ{correct_answer}ã€ï¼Œä¸¦ç°¡å–®è§£é‡‹ä¸€ä¸‹é»è§£ä¿‚å‘¢å€‹ç­”æ¡ˆï¼Œç›¡é‡ç”¨å­¸ç”Ÿæ˜“æ˜å˜…æ–¹å¼è¬›è§£ã€‚"""
    elif attempt == 2:
        tone = "é€²ä¸€æ­¥é¼“å‹µ"
        task = f"""è«‹ä½ å””å¥½è©±ç­”æ¡ˆï¼Œä½†å¯ä»¥æŒ‡å‡ºé—œéµæç¤ºæˆ–ç·šç´¢ï¼Œå¼•å°å­¸ç”Ÿè«—åˆ°ç­”æ¡ˆï¼Œå¹«ä½¢ç¸®çª„æ–¹å‘ã€‚"""
    else:  # attempt == 1
        tone = "è¼•é¬†é¼“å‹µ"
        task = f"""è«‹ä½ åªçµ¦ä¸€å€‹å¥½ç´°å¾®ã€å””å¤ªæ˜é¡¯å˜…æç¤ºï¼Œå¹«å­¸ç”Ÿè‡ªå·±å†è«—è«—ï¼Œå””å¥½ç›´æ¥è©±å‡ºé‡é»ã€‚"""

    prompt = f"""
        ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

        å­¸ç”Ÿå˜—è©¦å’—ç­”ä¸€æ¢å•é¡Œï¼š
        æ–‡ç« ï¼š{passage}
        å•é¡Œï¼š{question_text}
        å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}
        æ¨™æº–ç­”æ¡ˆï¼š{correct_answer}

        è«‹ä½ ç”¨{tone}èªæ°£ï¼Œ{task}

        è«‹ç”¨ 100-200 å­—å…§å»£æ±è©±å›ç­”ã€‚
        """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_reading,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


def ask_why_correct(question_text: str, user_answer: str, passage: str) -> str:
    """
    Only call when the answer is incorrect
    Asking the student to reflect on why they chose their (correct) answer.

    Parameters:
        question_text (str): The original question.
        user_answer (str): The student's correct answer.
        passage (str): The passage content for context.

    Returns:
        str: Cantonese prompt asking the student for reflection.
    """
    prompt = f"""
        ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

        å­¸ç”Ÿå•±å•±ç­”å•±å’—ä¸€æ¢å•é¡Œï¼Œä½ æƒ³é‚€è«‹ä½¢è¬›å“ä½¢é»è§£æœƒå’ç­”ï¼Œé¼“å‹µä½¢åæ€è‡ªå·±å˜…æ€è€ƒéç¨‹ã€‚

        ä½ è¦æ ¹æ“šä»¥ä¸‹è³‡æ–™ï¼Œç”¨ä¸€å€‹è¼•é¬†ã€è¦ªåˆ‡ã€é¼“å‹µæ€§å˜…èªæ°£å•ä½¢ï¼š
        - ä½ é»è§£æœƒå’ç­”ï¼Ÿ
        - æœ‰å†‡é‚Šå¥ä»¤ä½ ç‰¹åˆ¥æœ‰æ„Ÿè¦ºï¼Ÿ
        - å¦‚æœä½ ç”¨è‡ªå·±èªªæ³•ï¼Œå¯ä»¥é»è§£é‡‹ï¼Ÿ

        å•é¡Œï¼š{question_text}
        å­¸ç”Ÿç­”æ¡ˆï¼š{user_answer}
        æ–‡ç« ï¼š{passage}

        è«‹ç”¨ 80â€“150 å­—å»£æ±è©±å›æ‡‰ã€‚
        """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_reading,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


def respond_to_reflection(
    reflection_text: str, question_text: str, correct_answer: str, passage: str
) -> str:
    """
    Generates a response to a student's reflective answer (e.g., "why did you choose that?"),
    providing affirmation, insight, and constructive support in Cantonese.

    Parameters:
        reflection_text (str): The student's explanation or reflection.
        question_text (str): The original question.
        correct_answer (str): The model answer.
        passage (str): The relevant passage text.

    Returns:
        str: A warm Cantonese reply affirming and engaging with the studentâ€™s reasoning.
    """
    prompt = f"""
ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å˜…è€å¸«ã€‚

å­¸ç”Ÿå•±å•±å›ç­”å’—ä½ ä¹‹å‰å•ä½¢ï¼šã€Œä½ é»è§£æœƒå’ç­”å‘¢ï¼Ÿã€ä¾å®¶ä½¢åˆ†äº«å’—ä½¢å˜…è«—æ³•ã€‚

è«‹ä½ æ ¹æ“šä½¢å˜…å›æ‡‰ï¼Œç”¨è¦ªåˆ‡ã€é¼“å‹µã€å°è©±å¼å˜…èªæ°£ï¼š
1. è‚¯å®šä½¢é¡˜æ„åˆ†äº«è‡ªå·±å˜…æƒ³æ³•
2. è©•åƒ¹ä½¢å˜…è§£é‡‹ï¼ŒæŒ‡å‡ºæœ‰æ·±åº¦ï¼å‰µæ„ï¼é‚è¼¯æ€§
3. å¦‚æœä½¢æœ‰å•²ç´°ç¯€æœªæŒæ¡ï¼Œå¯ä»¥è¼•è¼•æŒ‡å‡ºä¸¦è£œå……
4. å¯ä»¥å¼•ç”¨æ–‡ç« ä¸€å°å¥ä½œä½è­‰

è«‹ç”¨ 80â€“150 å­—å»£æ±è©±å›æ‡‰ã€‚

ğŸ“ å­¸ç”Ÿå›æ‡‰ï¼š{reflection_text}
â“ åŸå•é¡Œï¼š{question_text}
âœ… æ¨™æº–ç­”æ¡ˆï¼š{correct_answer}
ğŸ“– æ–‡ç« ï¼š{passage}
"""

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_reading,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


def respond_to_open_answer(user_answer: str, question_text: str) -> str:
    prompt = f"""
ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™é–±è®€ç†è§£å˜…è‹±æ–‡è€å¸«ã€‚

å­¸ç”Ÿå›æ‡‰å’—ä¸€æ¢é–‹æ”¾å¼å•é¡Œã€‚ä½ è¦ç”¨é¼“å‹µã€åæ€å¼èªæ°£å›æ‡‰ï¼š
- è‚¯å®šä½¢å˜…è«—æ³•
- å›æ‡‰ä½¢å…§å®¹ï¼ˆå¯ä»¥å¼•ç”¨éƒ¨åˆ†å›ç­”ï¼‰
- é¼“å‹µä½¢å†æ€è€ƒä¸€å±¤ï¼ˆä¾‹å¦‚ï¼šä½ è¦ºå¾—å¦‚æœä¿‚ä½ æœƒé»åšï¼Ÿï¼‰

ğŸ“ å•é¡Œï¼š{question_text}
ğŸ’¬ å­¸ç”Ÿå›æ‡‰ï¼š{user_answer}

è«‹ç”¨ 80â€“120 å­—å»£æ±è©±å›ç­”ã€‚
"""
    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {"role": "system", "content": system_prompt_reading},
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


"""
##############
VOCAB EXERCISE
##############
"""


def ask_vocab_meaning_question(vocab_row: dict) -> str:
    """
    Generate message asking the student if they know the meaning of a vocabulary word.

    Parameters:
        vocab_row (dict): A single vocab record (from the vocab sheet).

    Returns:
        str: Cantonese prompt asking if the student knows the word meaning.
    """
    vocab = vocab_row["Vocabulary"]
    part_of_speech = vocab_row["PartOfSpeech"]

    prompt = f"""
        ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å–®å­—å˜…è€å¸«ï¼Œæ“…é•·ç”¨é¼“å‹µæ€§ã€è¦ªåˆ‡æ–¹å¼å¼•å°å­¸ç”Ÿã€‚

        è«‹ä½ å¹«æˆ‘æ’°å¯«ä¸€æ®µè¨Šæ¯ï¼Œèªæ°£æº«æŸ”æœ‰è¶£ï¼Œé¼“å‹µå­¸ç”Ÿå›ç­”ä»¥ä¸‹å•é¡Œï¼š

        ã€Œä½ çŸ¥å””çŸ¥é“ â€œ{vocab}â€ å‘¢å€‹å­—å˜…æ„æ€ä¿‚å’©ï¼Ÿã€

        è«‹é¼“å‹µå­¸ç”Ÿå””æ´—é©šè¬›éŒ¯ï¼Œå¯ä»¥è‡ªç”±ä¼°ä¸‹ï¼Œå””éœ€è¦çµ¦æç¤ºã€ä¾‹å¥æˆ–è§£é‡‹ã€‚
        å””éœ€è¦åŒåŒå­¸æ‰“æ‹›å‘¼ï¼Œç›´æ¥å•å•é¡Œå°±å¯ä»¥äº†

        è«‹ç”¨ 30-40 å­—å»£æ±è©±å›æ‡‰ã€‚

        template 1: "æˆ‘å“‹åšŸå­¸å€‹æ–°å­—ã€Œpastureã€å•¦ã€‚ä½ çŸ¥å””çŸ¥é“å‘¢å€‹ noun å˜…æ„æ€ä¿‚å’©å‘€ï¼Ÿå””æ´—æ€•è¬›éŒ¯ï¼Œéš¨å¿ƒæ‰€æ¬²ä¼°ä¸‹ï¼Œåªè¦ä½ è‚¯è«—å°±å¾—ã—ï¼è©¦ä¸‹è©±ä¿¾æˆ‘è½å•¦ï¼ğŸ˜Š"
        template 2: "è¦‹åˆ°ä½ å’ç©æ¥µæƒ³å­¸æ–°è©ï¼Œæˆ‘å¥½é–‹å¿ƒå‘€ï¼ç­‰æˆ‘å•ä½ ä¸€å€‹å•é¡Œå•¦ï¼Œæ”¾è¼•é¬†ï¼Œè‡ªç”±å•²ä¼°ä¸‹å°±å¾—ï¼ä½ çŸ¥å””çŸ¥é“ â€œpastureâ€ å‘¢å€‹ noun å˜…æ„æ€ä¿‚å’©ï¼Ÿ å””æ€•è¬›éŒ¯ï¼Œç›¡æƒ…åˆ†äº«ä½ å˜…æƒ³æ³•å•¦ï¼ğŸ˜Š"
        """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_vocab,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


def give_vocab_correct_reply(vocab_row: dict) -> str:
    """
    Generate a Cantonese message that praises the student
    for answering a vocabulary word correctly and reinforces the meaning.

    Parameters:
        vocab_row (dict): The vocabulary entry that was just answered correctly.

    Returns:
        str: A warm and encouraging message in Cantonese.
    """
    vocab = vocab_row["Vocabulary"]
    part_of_speech = vocab_row["PartOfSpeech"]
    meaning_zh = vocab_row["ChineseExplaination"]
    example = vocab_row["Examples"]
    root = vocab_row["Roots"]
    mem_story = vocab_row["MemStories"]

    prompt = f"""
ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å–®å­—å˜…è€å¸«ã€‚

å­¸ç”Ÿå•±å•±æˆåŠŸå›ç­”å’— â€œ{vocab}â€ å‘¢å€‹ {part_of_speech} å˜…æ„æ€ã€‚

è«‹ä½ æ’°å¯«ä¸€æ®µ 60â€“100 å­—å·¦å³å˜…è¨Šæ¯ï¼š
1. ç¨±è®šå­¸ç”Ÿ
2. è‚¯å®šä½¢ç­”å•±å’—ï¼Œä¸¦é‡ç”³æ„æ€ä¿‚ã€Œ{meaning_zh}ã€
3. å¯ä»¥æä¸€æä¾‹å¥ï¼šã€Œ{example}ã€æˆ–è¨˜æ†¶æ³•ï¼šã€Œ{mem_story}ã€
4. å¯ä»¥è§£é‡‹ä¸€ä¸‹è©æ ¹ï¼š{root}
4. ç¹¼çºŒæŒ‘æˆ°ä¸‹ä¸€å€‹å­—

è«‹ç”¨è¦ªåˆ‡ã€é¼“å‹µã€è‡ªç„¶å˜…èªæ°£å›è¦†ã€‚åªç”¨å»£æ±è©±ï¼Œä¸è¦è‹±æ–‡è§£é‡‹ã€‚
é¿å…ä½¿ç”¨æ€§åˆ¥å­—å½™ e.g. å»å¥³/å»ä»”
"""

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_vocab,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()


def give_vocab_hint_or_explanation(vocab_row: dict, attempt: int) -> str:
    """
    Uses LLM to provide either a hint (first attempt) or a full explanation
    (second attempt) for a vocabulary word, based on student progress.

    Parameters:
        vocab_row (dict): The vocabulary entry for today.
        attempt (int): Attempt number (1 or 2).

    Returns:
        str: A friendly Cantonese teaching message.
    """
    vocab = vocab_row["Vocabulary"]
    part_of_speech = vocab_row["PartOfSpeech"]
    example = vocab_row["Examples"]
    meaning_zh = vocab_row["ChineseExplaination"]
    tip = vocab_row["Tips"]
    root = vocab_row["Roots"]
    mem_story = vocab_row["MemStories"]

    if attempt not in [1, 2]:
        raise ValueError("Attempt must be either 1 or 2.")

    if attempt == 1:
        tone = "è¼•é¬†é¼“å‹µ"
        task = f"""
            å­¸ç”Ÿç¬¬ä¸€æ¬¡ç­”éŒ¯ï¼Œè«‹ä½ ï¼š
            1. é‡æå‘¢å€‹ä¾‹å¥ï¼š{example}
            2. ç”¨è¦ªåˆ‡èªæ°£å¼•å°ä½¢å†ä¼°ä¸€æ¬¡
            3. å¯åŠ è¼•å¾®æç¤ºï¼ˆä¾‹å¦‚ï¼šä½ å¯ä»¥è«—å“ã€Œ{tip}ã€ï¼‰
            4. å””å¥½ç›´æ¥è¬›ç­”æ¡ˆæˆ–è§£é‡‹

            template 1: å””ç·Šè¦å‘€ï¼Œç¬¬ä¸€æ¬¡å””å•±ä¿‚å¥½æ­£å¸¸ã—ï¼ç­‰æˆ‘å“‹ä¸€é½Šç‡ä¸‹ä¸€å¥å¥å­ï¼šCows graze in the green pasture. è«—å“å€‹å¥å­ä¿‚è¬›å’©å˜…å‘¢ï¼Ÿç‰›ç‰›å–ºé‚Šåº¦é£Ÿè‰å‘¢ï¼Ÿ ä½ å†è©¦å“ä¼°ä¸‹ "pasture" å˜…æ„æ€ï¼Œå””ä½¿æ€•è¬›éŒ¯
            """
    else:
        tone = "æº«æŸ”è§£é‡‹"
        task = f"""
            å­¸ç”Ÿç¬¬äºŒæ¬¡éƒ½æœªä¼°ä¸­ï¼Œè«‹ä½ ï¼š
            1. å‘Šè¨´ä½¢ â€œ{vocab}â€ å‘¢å€‹ {part_of_speech} å˜…ä¸­æ–‡æ„æ€ä¿‚ï¼š{meaning_zh}
            2. å¼•ç”¨è¨˜æ†¶æ•…äº‹ï¼šã€Œ{mem_story}ã€
            3. å¯ä»¥è§£é‡‹ä¸€ä¸‹è©æ ¹ï¼š{root}
            4. é¼“å‹µä½¢è¨˜ä½å–®å­—ï¼Œä¸¦é‚€è«‹ä½¢ç¹¼çºŒå‰å¾€ä¸‹ä¸€å€‹è©å½™
            """

    prompt = f"""
        ä½ ä¿‚ä¸€ä½ç”¨å»£æ±è©±æ•™è‹±æ–‡å–®å­—å˜…è€å¸«ã€‚

        å­¸ç”Ÿå­¸ç·Š â€œ{vocab}â€ å‘¢å€‹ {part_of_speech}ï¼Œä½†æœªæŒæ¡æ„æ€ã€‚

        {task}

        è«‹ç”¨ {tone} å˜…èªæ°£ï¼Œç”¨å»£æ±è©±å¯«ä¸€æ®µè‡ªç„¶ã€é¼“å‹µæ€§æ•™å­¸è¨Šæ¯ã€‚
        """

    response = client.chat.completions.create(
        model="google/gemma-3-27b-it",
        messages=[
            {
                "role": "system",
                "content": system_prompt_vocab,
            },
            {"role": "user", "content": prompt},
        ],
    )

    return response.choices[0].message.content.strip()
